{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1681009672158,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "D3V75bH2UnEm"
   },
   "outputs": [],
   "source": [
    "# %load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11140,
     "status": "ok",
     "timestamp": 1681009683293,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "ZbQyFuvWUnEu",
    "outputId": "eff0b749-4e4d-40d1-8fd2-eb9fcbc1335d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENVIRONMENT: Colab\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Working directory is: /content/drive/MyDrive/MIDS/w266/w266-project-carlos\n"
     ]
    }
   ],
   "source": [
    "# Set for local or colab\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "\n",
    "# Check if running in colab\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "# Project defaults\n",
    "if IN_COLAB:\n",
    "    print(\"ENVIRONMENT: Colab\")\n",
    "\n",
    "    # Mount drive\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    # Set the project directory\n",
    "    PROJECT_FOLDER = \"/content/drive/MyDrive/MIDS/w266/w266-project-carlos\"\n",
    "\n",
    "    # Install dependencies\n",
    "    !pip install -q transformers datasets SentencePiece\n",
    "\n",
    "    # Set timezone\n",
    "    !rm /etc/localtime\n",
    "    !ln -s /usr/share/zoneinfo/US/Pacific /etc/localtime\n",
    "\n",
    "else:\n",
    "    print(\"ENVIRONMENT: Local\")\n",
    "    # Set the project directory\n",
    "    PROJECT_FOLDER = \"/user/w266/w266-project-carlos\"\n",
    "\n",
    "os.chdir(PROJECT_FOLDER)\n",
    "\n",
    "# FOLDERS\n",
    "DATASET_FOLDER = join(PROJECT_FOLDER, \"dataset/dataset_final\")\n",
    "EXPERIMENT_BASE_FOLDER = join(PROJECT_FOLDER, \"experiments\")\n",
    "EXPERIMENT_RESULTS_FOLDER = join(PROJECT_FOLDER, \"experiment_results\")\n",
    "NVBENCH_DIRECTORY = join(PROJECT_FOLDER, \"ref_repos/nvBench/database\")\n",
    "\n",
    "print(f\"Working directory is: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9176,
     "status": "ok",
     "timestamp": 1681009692442,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "uVG_YCObUnEx"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "from t5_model_support_functions import (\n",
    "    load_csv_files,\n",
    "    token_to_df,\n",
    "    get_string_equality,\n",
    "    get_pd_row_accuracy,\n",
    "    attach_nvBench_info,\n",
    "    build_vega_zero_source,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzwwLeDPUnEy"
   },
   "source": [
    "### Load `csv` data as `dataframes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2843,
     "status": "ok",
     "timestamp": 1681009695260,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "qlaGnYxgUnE0",
    "outputId": "555ce9bc-4eae-442c-e882-75be0d8b532a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 'train.csv'\n",
      "Number of records in /content/drive/MyDrive/MIDS/w266/w266-project-carlos/dataset/dataset_final/train.csv: 25238\n",
      "\n",
      "Loading 'dev.csv'\n",
      "Number of records in /content/drive/MyDrive/MIDS/w266/w266-project-carlos/dataset/dataset_final/dev.csv: 1430\n",
      "-> Merged!!\n",
      "\n",
      "Loading 'test.csv'\n",
      "Number of records in /content/drive/MyDrive/MIDS/w266/w266-project-carlos/dataset/dataset_final/test.csv: 4920\n",
      "-> Merged!!\n",
      "\n",
      "Focusing on the following columns: ['source', 'labels', 'token_types']\n",
      "\n",
      "Searching for duplicate rows in focus columns...\n",
      "A total of 31544 records were loaded (44 records dropped after duplicate filter)\n",
      "\n",
      "Seaching for NaN fields in foclus columns...\n",
      "Rows with NaN values: 0\n",
      "Dropping NaN...\n",
      "\n",
      "Final total records 31544\n",
      "\n",
      "returning 3 files\n"
     ]
    }
   ],
   "source": [
    "TARGET_FEATURES = [\"source\", \"labels\", \"token_types\"]\n",
    "\n",
    "df_train, df_val, df_test = load_csv_files(\n",
    "    [\n",
    "        join(DATASET_FOLDER, \"train.csv\"),\n",
    "        join(DATASET_FOLDER, \"dev.csv\"),\n",
    "        join(DATASET_FOLDER, \"test.csv\"),\n",
    "    ],\n",
    "    focus_columns=TARGET_FEATURES,\n",
    "    drop_duplicates=True,\n",
    "    dropna=True,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvAzbg67mgUP"
   },
   "source": [
    "#### Ataching nvBench info and building new sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 96921,
     "status": "ok",
     "timestamp": 1681009792175,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "VD8AO-6PmgUP"
   },
   "outputs": [],
   "source": [
    "## nvBench Info\n",
    "df_train = attach_nvBench_info(df_train, NVBENCH_DIRECTORY)\n",
    "df_val = attach_nvBench_info(df_val, NVBENCH_DIRECTORY)\n",
    "df_test = attach_nvBench_info(df_test, NVBENCH_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1237,
     "status": "ok",
     "timestamp": 1681009793382,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "UgMH46btmgUQ"
   },
   "outputs": [],
   "source": [
    "# Rebuilding the source to only include the \"used columns\"\n",
    "df_train[\"source_new\"] = df_train.apply(\n",
    "    build_vega_zero_source, axis=1, args=[\"columns_used\", 2]\n",
    ")\n",
    "\n",
    "df_val[\"source_new\"] = df_val.apply(\n",
    "    build_vega_zero_source, axis=1, args=[\"columns_used\", 2]\n",
    ")\n",
    "\n",
    "df_test[\"source_new\"] = df_test.apply(\n",
    "    build_vega_zero_source, axis=1, args=[\"columns_used\", 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CH1cOLI8UnE1"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_X8UDEkUnE4"
   },
   "source": [
    "#### Set experiment folder and architectbase model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681009793383,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "2w7dwhUi5Lcg",
    "outputId": "aeaee54b-4277-4945-c81e-1bb91e196c95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device type: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device type: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 44877,
     "status": "ok",
     "timestamp": 1681009838255,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "fZqa9jz2UnE4"
   },
   "outputs": [],
   "source": [
    "# EXPERIMENT_NAME = \"exp_01_t5-base\"\n",
    "# MODEL_TYPE = \"t5-base\"\n",
    "\n",
    "# EXPERIMENT_NAME = \"exp_02_codet5-base\"\n",
    "# MODEL_TYPE = \"codet5-base\"\n",
    "\n",
    "EXPERIMENT_NAME = \"exp_03_codet5-large\"\n",
    "MODEL_TYPE = \"codet5-large\"\n",
    "\n",
    "EXPERIMENT_FOLDER = join(EXPERIMENT_BASE_FOLDER, EXPERIMENT_NAME)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(EXPERIMENT_FOLDER).to(device)\n",
    "\n",
    "if \"codet5\" in MODEL_TYPE:\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(join(EXPERIMENT_FOLDER, \"tokenizer\"))\n",
    "else:\n",
    "    tokenizer = T5Tokenizer.from_pretrained(join(EXPERIMENT_FOLDER, \"tokenizer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j61L23ZWUnE2"
   },
   "source": [
    "#### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1681009838256,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "TsCrMnfuUnE3",
    "outputId": "79dc5a38-596a-475f-ecb2-735270abaa21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches: 163\n"
     ]
    }
   ],
   "source": [
    "prefix = \"Generate vega_zero code: \"\n",
    "max_input_length = 162\n",
    "max_target_length = 60\n",
    "batch_size = 30\n",
    "\n",
    "DEV_TESTING = False\n",
    "DEV_LENGTH = 6\n",
    "\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Calculated\n",
    "\n",
    "set_len = DEV_LENGTH if DEV_TESTING else len(df_test)\n",
    "total_batches = int(np.ceil(set_len / batch_size))\n",
    "print(f\"Total number of batches: {total_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1681009838520,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "Z--ksKqaUnE5"
   },
   "outputs": [],
   "source": [
    "if DEV_TESTING:\n",
    "    train_dataset = Dataset.from_pandas(df_train.head(DEV_LENGTH), split=\"train\")\n",
    "    val_dataset = Dataset.from_pandas(df_val.head(DEV_LENGTH), split=\"validation\")\n",
    "    test_dataset = Dataset.from_pandas(df_test.head(DEV_LENGTH), split=\"test\")\n",
    "else:\n",
    "    train_dataset = Dataset.from_pandas(df_train, split=\"train\")\n",
    "    val_dataset = Dataset.from_pandas(df_val, split=\"validation\")\n",
    "    test_dataset = Dataset.from_pandas(df_test, split=\"test\")\n",
    "\n",
    "\n",
    "columns = [\"tvBench_id\", \"hardness\", \"source\", \"labels\", \"source_new\"]\n",
    "\n",
    "# This sets what is pulled when batching\n",
    "train_dataset.set_format(type=\"torch\", columns=columns)\n",
    "val_dataset.set_format(type=\"torch\", columns=columns)\n",
    "test_dataset.set_format(type=\"torch\", columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1681009838521,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "d8WkynAMUnE6",
    "outputId": "84d1ac19-49f7-4f8b-a2d0-63a4e7c659a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Dataset({\n",
      "    features: ['tvBench_id', 'db_id', 'chart', 'hardness', 'query', 'question', 'vega_zero', 'mentioned_columns', 'mentioned_values', 'query_template', 'source', 'labels', 'token_types', 'table', 'nvBench_column_names', 'columns_used', 'source_new', '__index_level_0__'],\n",
      "    num_rows: 25238\n",
      "})\n",
      "****************************************************************************************************\n",
      "Validation\n",
      "Dataset({\n",
      "    features: ['tvBench_id', 'db_id', 'chart', 'hardness', 'query', 'question', 'vega_zero', 'mentioned_columns', 'mentioned_values', 'query_template', 'source', 'labels', 'token_types', 'table', 'nvBench_column_names', 'columns_used', 'source_new', '__index_level_0__'],\n",
      "    num_rows: 1430\n",
      "})\n",
      "****************************************************************************************************\n",
      "Test\n",
      "Dataset({\n",
      "    features: ['tvBench_id', 'db_id', 'chart', 'hardness', 'query', 'question', 'vega_zero', 'mentioned_columns', 'mentioned_values', 'query_template', 'source', 'labels', 'token_types', 'table', 'nvBench_column_names', 'columns_used', 'source_new', '__index_level_0__'],\n",
      "    num_rows: 4876\n",
      "})\n",
      "dict_keys(['tvBench_id', 'hardness', 'source', 'labels', 'source_new'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Training\")\n",
    "print(train_dataset)\n",
    "print(\"*\" * 100)\n",
    "\n",
    "print(\"Validation\")\n",
    "print(val_dataset)\n",
    "print(\"*\" * 100)\n",
    "\n",
    "print(\"Test\")\n",
    "print(test_dataset)\n",
    "\n",
    "# Without the `.set_format`, this would get you all the columns\n",
    "print(train_dataset[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1681009838522,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "WWTzDPUbUnE7"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1067548,
     "status": "ok",
     "timestamp": 1681010906065,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "kDTLoEtDUnE7",
    "outputId": "b66c2e0e-fcf3-44e3-d300-e5f69759ea6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing started 04/08/2023 08:10 PM\n",
      "Processing batch 1 of 163...COMPLETE! (15 seconds)\n",
      "Processing batch 2 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 3 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 4 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 5 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 6 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 7 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 8 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 9 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 10 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 11 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 12 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 13 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 14 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 15 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 16 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 17 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 18 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 19 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 20 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 21 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 22 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 23 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 24 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 25 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 26 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 27 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 28 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 29 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 30 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 31 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 32 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 33 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 34 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 35 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 36 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 37 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 38 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 39 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 40 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 41 of 163...COMPLETE! (4 seconds)\n",
      "Processing batch 42 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 43 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 44 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 45 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 46 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 47 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 48 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 49 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 50 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 51 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 52 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 53 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 54 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 55 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 56 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 57 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 58 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 59 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 60 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 61 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 62 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 63 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 64 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 65 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 66 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 67 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 68 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 69 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 70 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 71 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 72 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 73 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 74 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 75 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 76 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 77 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 78 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 79 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 80 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 81 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 82 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 83 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 84 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 85 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 86 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 87 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 88 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 89 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 90 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 91 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 92 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 93 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 94 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 95 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 96 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 97 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 98 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 99 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 100 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 101 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 102 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 103 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 104 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 105 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 106 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 107 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 108 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 109 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 110 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 111 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 112 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 113 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 114 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 115 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 116 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 117 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 118 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 119 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 120 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 121 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 122 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 123 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 124 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 125 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 126 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 127 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 128 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 129 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 130 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 131 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 132 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 133 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 134 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 135 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 136 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 137 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 138 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 139 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 140 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 141 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 142 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 143 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 144 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 145 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 146 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 147 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 148 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 149 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 150 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 151 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 152 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 153 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 154 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 155 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 156 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 157 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 158 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 159 of 163...COMPLETE! (6 seconds)\n",
      "Processing batch 160 of 163...COMPLETE! (7 seconds)\n",
      "Processing batch 161 of 163...COMPLETE! (5 seconds)\n",
      "Processing batch 162 of 163...COMPLETE! (4 seconds)\n",
      "Processing batch 163 of 163...COMPLETE! (3 seconds)\n",
      "Processing finished 04/08/2023 08:28 PM (1066 seconds)\n"
     ]
    }
   ],
   "source": [
    "tvBench_id = []\n",
    "hardness = []\n",
    "sources = []\n",
    "labels = []\n",
    "predictions = []\n",
    "\n",
    "start_time = iter_start_time = datetime.now()\n",
    "print(f\"Processing started {start_time.strftime('%m/%d/%Y %I:%M %p')}\")\n",
    "\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    print(f\"Processing batch {i+1} of {total_batches}...\", end=\"\")\n",
    "\n",
    "    # Process batches\n",
    "    texts = [prefix + src for src in batch[\"source_new\"]]\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        texts,\n",
    "        max_length=max_input_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **encoding,\n",
    "            num_beams=3,\n",
    "            min_length=15,\n",
    "            max_length=max_target_length,\n",
    "        )\n",
    "\n",
    "        predictions.extend(\n",
    "            tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        )\n",
    "\n",
    "    sources.extend(batch[\"source_new\"])\n",
    "    labels.extend(batch[\"labels\"])\n",
    "    hardness.extend(batch[\"hardness\"])\n",
    "    tvBench_id.extend(batch[\"tvBench_id\"])\n",
    "\n",
    "    # Update timers\n",
    "    iter_end_time = datetime.now()\n",
    "    print(f\"COMPLETE! ({(iter_end_time - iter_start_time).seconds} seconds)\")\n",
    "    iter_start_time = datetime.now()\n",
    "\n",
    "end_time = datetime.now()\n",
    "time_span = end_time - start_time\n",
    "print(\n",
    "    f\"Processing finished {end_time.strftime('%m/%d/%Y %I:%M %p')} ({time_span.seconds} seconds)\"\n",
    ")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1681010906534,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "pDtLVLbvUnE8",
    "outputId": "03fd9404-988c-4ae9-f132-b4beb7710135"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-16001459-822e-46a1-beea-240f1fd29c0e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tvBench_id</th>\n",
       "      <th>hardness</th>\n",
       "      <th>source</th>\n",
       "      <th>labels</th>\n",
       "      <th>prediction</th>\n",
       "      <th>percent_equal</th>\n",
       "      <th>equal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3092@y_name@DESC</td>\n",
       "      <td>Medium</td>\n",
       "      <td>&lt;N&gt; Give me the comparison about Team_ID over ...</td>\n",
       "      <td>mark bar data basketball_match encoding x all_...</td>\n",
       "      <td>mark bar data basketball_match encoding x all_...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3092@y_name@DESC</td>\n",
       "      <td>Medium</td>\n",
       "      <td>&lt;N&gt; Give me the comparison about Team_ID over ...</td>\n",
       "      <td>mark bar data basketball_match encoding x all_...</td>\n",
       "      <td>mark bar data basketball_match encoding x all_...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2818@y_name@DESC</td>\n",
       "      <td>Hard</td>\n",
       "      <td>&lt;N&gt; Give me a histogram for what is the number...</td>\n",
       "      <td>mark bar data player encoding x position y agg...</td>\n",
       "      <td>mark bar data player encoding x position y agg...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2818@y_name@DESC</td>\n",
       "      <td>Hard</td>\n",
       "      <td>&lt;N&gt; Give me a histogram for what is the number...</td>\n",
       "      <td>mark bar data player encoding x position y agg...</td>\n",
       "      <td>mark bar data player encoding x position y agg...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2681@x_name@ASC</td>\n",
       "      <td>Medium</td>\n",
       "      <td>&lt;N&gt; Show different occupations along with the ...</td>\n",
       "      <td>mark bar data player encoding x occupation y a...</td>\n",
       "      <td>mark bar data player encoding x occupation y a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16001459-822e-46a1-beea-240f1fd29c0e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-16001459-822e-46a1-beea-240f1fd29c0e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-16001459-822e-46a1-beea-240f1fd29c0e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         tvBench_id hardness  \\\n",
       "0  3092@y_name@DESC   Medium   \n",
       "1  3092@y_name@DESC   Medium   \n",
       "2  2818@y_name@DESC     Hard   \n",
       "3  2818@y_name@DESC     Hard   \n",
       "4   2681@x_name@ASC   Medium   \n",
       "\n",
       "                                              source  \\\n",
       "0  <N> Give me the comparison about Team_ID over ...   \n",
       "1  <N> Give me the comparison about Team_ID over ...   \n",
       "2  <N> Give me a histogram for what is the number...   \n",
       "3  <N> Give me a histogram for what is the number...   \n",
       "4  <N> Show different occupations along with the ...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  mark bar data basketball_match encoding x all_...   \n",
       "1  mark bar data basketball_match encoding x all_...   \n",
       "2  mark bar data player encoding x position y agg...   \n",
       "3  mark bar data player encoding x position y agg...   \n",
       "4  mark bar data player encoding x occupation y a...   \n",
       "\n",
       "                                          prediction  percent_equal  equal  \n",
       "0  mark bar data basketball_match encoding x all_...            1.0    1.0  \n",
       "1  mark bar data basketball_match encoding x all_...            1.0    1.0  \n",
       "2  mark bar data player encoding x position y agg...            1.0    1.0  \n",
       "3  mark bar data player encoding x position y agg...            1.0    1.0  \n",
       "4  mark bar data player encoding x occupation y a...            1.0    1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame()\n",
    "df_results[\"tvBench_id\"] = tvBench_id\n",
    "df_results[\"hardness\"] = hardness\n",
    "df_results[\"source\"] = sources\n",
    "df_results[\"labels\"] = labels\n",
    "df_results[\"prediction\"] = predictions\n",
    "\n",
    "df_results[\"percent_equal\"] = df_results.apply(get_pd_row_accuracy, axis=1)\n",
    "df_results[\"equal\"] = df_results[\"percent_equal\"].apply(\n",
    "    lambda var: 1.0 if var == 1.0 else 0.0\n",
    ")\n",
    "\n",
    "\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1681010907050,
     "user": {
      "displayName": "Carlos Crespo",
      "userId": "14842697702706520683"
     },
     "user_tz": 420
    },
    "id": "fkKrSvj9SY4N",
    "outputId": "dc081d90-c7d7-4116-f866-8686cdfb66d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving 'exp_03_codet5-large_results_2023_04_08-20_28.csv'\n"
     ]
    }
   ],
   "source": [
    "file_name = f\"{EXPERIMENT_NAME}_results_{end_time.strftime('%Y_%m_%d-%H_%M')}.csv\"\n",
    "\n",
    "print(f\"saving '{file_name}'\")\n",
    "\n",
    "df_results.to_csv(join(EXPERIMENT_RESULTS_FOLDER,file_name),index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
